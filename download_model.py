# download_model.py
# –ü–æ–ª–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è: –º–æ–¥–µ–ª—å, NLTK, .env —Å —Ç–æ–∫–µ–Ω–æ–º
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python download_model.py

import os
import sys
import requests
import zipfile
import argparse
from getpass import getpass

# --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π ---
def install_dependencies():
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç"""
    required = ["requests", "nltk", "transformers", "torch", "python-dotenv"]
    for package in required:
        try:
            __import__(package.replace("-", "_"))
        except ImportError:
            print(f"üì¶ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º {package}...")
            import subprocess
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ NLTK ---
def setup_nltk():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ NLTK"""
    import nltk

    nltk_data_dir = os.path.join(os.getcwd(), "nltk_data")
    os.makedirs(nltk_data_dir, exist_ok=True)
    if nltk_data_dir not in nltk.data.path:
        nltk.data.path.insert(0, nltk_data_dir)

    print("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º NLTK –¥–∞–Ω–Ω—ã–µ: punkt_tab –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞...")
    try:
        nltk.data.find('tokenizers/punkt_tab/russian/')
        print("‚úÖ punkt_tab —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    except LookupError:
        print("üì• –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º punkt_tab...")
        nltk.download('punkt_tab', download_dir=nltk_data_dir)
    print(f"üíæ NLTK –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {nltk_data_dir}")

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞ ---
def download_model():
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∏ —Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ—Ç –º–æ–¥–µ–ª—å —É–ø—Ä–æ—â–µ–Ω–∏—è"""
    PUBLIC_LINK = "https://disk.yandex.ru/d/Ux1wDo_P1s0x6Q"
    MODEL_DIR = "model/rut5_simplifier_new"
    ZIP_PATH = "model/rut5_simplifier.zip"

    os.makedirs("model", exist_ok=True)

    if os.path.exists(MODEL_DIR):
        print(f"‚úÖ –ú–æ–¥–µ–ª—å —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {MODEL_DIR}")
        return MODEL_DIR

    print("üîó –ü–æ–ª—É—á–∞–µ–º –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ...")
    try:
        api_url = "https://cloud-api.yandex.net/v1/disk/public/resources/download"
        response = requests.get(api_url, params={"public_key": PUBLIC_LINK})
        response.raise_for_status()
        download_url = response.json()["href"]

        print("üì• –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å...")
        with requests.get(download_url, stream=True) as r:
            r.raise_for_status()
            with open(ZIP_PATH, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)
        print(f"‚úÖ –ê—Ä—Ö–∏–≤ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {ZIP_PATH}")

        print("üì¶ –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –º–æ–¥–µ–ª—å...")
        with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:
            zip_ref.extractall(MODEL_DIR)
        print(f"‚úÖ –ú–æ–¥–µ–ª—å —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω–∞ –≤: {MODEL_DIR}")

        os.remove(ZIP_PATH)
        print("üóëÔ∏è –í—Ä–µ–º–µ–Ω–Ω—ã–π –∞—Ä—Ö–∏–≤ —É–¥–∞–ª—ë–Ω")

        return MODEL_DIR

    except Exception as e:
        raise RuntimeError(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")

# --- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ .env –∏ —Ç–æ–∫–µ–Ω–æ–º ---
def setup_env(model_path):
    """–°–æ–∑–¥–∞—ë—Ç .env —Ñ–∞–π–ª —Å MODEL_PATH –∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç BOT_TOKEN, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç"""
    env_file = ".env"

    # –ß–∏—Ç–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
    env_vars = {}
    if os.path.exists(env_file):
        with open(env_file, "r") as f:
            for line in f:
                if "=" in line and not line.strip().startswith("#"):
                    key, value = line.strip().split("=", 1)
                    env_vars[key] = value

    # –û–±–Ω–æ–≤–ª—è–µ–º MODEL_PATH
    env_vars["MODEL_PATH"] = model_path

    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º BOT_TOKEN, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
    if "BOT_TOKEN" not in env_vars:
        print("\nüîê –í–≤–µ–¥–∏—Ç–µ —Ç–æ–∫–µ–Ω Telegram-–±–æ—Ç–∞ (–Ω–µ –≤–∏–¥–µ–Ω –ø—Ä–∏ –≤–≤–æ–¥–µ):")
        bot_token = getpass()
        if not bot_token or ":" not in bot_token:
            raise ValueError("‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ç–æ–∫–µ–Ω. –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ 123456789:ABCdefGhIJKlmnOPqrsTUVWXyz123456789")
        env_vars["BOT_TOKEN"] = bot_token

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    with open(env_file, "w") as f:
        for key, value in env_vars.items():
            f.write(f"{key}={value}\n")

    print(f"üìÑ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {env_file}")

# --- –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ---
def main():
    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è TextEaseBot...")

    # 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    install_dependencies()

    # 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ NLTK
    setup_nltk()

    # 3. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model_path = download_model()

    # 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ .env (—Å —Ç–æ–∫–µ–Ω–æ–º)
    setup_env(model_path)

    print("üéâ –ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –±–æ—Ç–∞: python bot.py")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è TextEaseBot")
    parser.add_argument('--force', action='store_true', help='–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å')
    args = parser.parse_args()

    if args.force:
        model_dir = "model/rut5_simplifier_new"
        if os.path.exists(model_dir):
            import shutil
            print("üîÅ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞: —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –º–æ–¥–µ–ª—å...")
            shutil.rmtree(model_dir)

    main()